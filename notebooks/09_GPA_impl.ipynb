{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GPA\n",
    "Generalized Procrustes analysis"
   ],
   "id": "9ad2e4ad2348ce21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:32:12.513339Z",
     "start_time": "2025-10-29T16:32:11.376698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def center_shape(x):\n",
    "    \"\"\"Removes translation by shifting the shape so that its centroid is at (0, 0).\"\"\"\n",
    "    return x - x.mean(dim=0, keepdim=True)\n",
    "\n",
    "\n",
    "def normalize_shape(x):\n",
    "    \"\"\"Scales the shape so that it has unit length (normalizes its size).\"\"\"\n",
    "    return x / torch.norm(x)\n",
    "\n",
    "\n",
    "def procrustes_align(x, y, only_matrix=False):\n",
    "    \"\"\"\n",
    "    Aligns shape X to shape Y by rotation (Procrustes alignment).\n",
    "    Assumes both shapes are already centered and normalized.\n",
    "    \"\"\"\n",
    "    # Orthogonal rotation matrix `r` computed via SVD\n",
    "    u, _, vt = torch.linalg.svd(x.T @ y)\n",
    "    r = u @ vt\n",
    "    if torch.det(r) < 0:\n",
    "        # det(r)<0 means that it is a flip, not a rotation\n",
    "        # flip last column of U\n",
    "        u[:, -1] *= -1\n",
    "        r = u @ vt\n",
    "    if only_matrix:\n",
    "        return r\n",
    "    return x @ r\n",
    "\n",
    "\n",
    "def generalized_procrustes_analysis(shapes, tol=1e-6, max_iter=100, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    Performs Generalized Procrustes Analysis (GPA) on a set of 2D shapes.\n",
    "\n",
    "    Args:\n",
    "        shapes (torch.Tensor): Tensor of shape (N, n_points, 2) containing N shapes.\n",
    "        tol (float): Convergence tolerance for mean shape updates.\n",
    "        max_iter (int): Maximum number of iterations allowed.\n",
    "        device (torch.device): Device on which to perform computations.\n",
    "\n",
    "    Returns:\n",
    "        mean_shape (torch.Tensor): The resulting mean shape of shape (n_points, 2).\n",
    "    \"\"\"\n",
    "    shapes = shapes.to(device, dtype=torch.float32)\n",
    "    shapes = torch.stack([normalize_shape(center_shape(s)) for s in shapes])\n",
    "    mean_shape = normalize_shape(shapes.mean(dim=0))\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        aligned = []\n",
    "        for s in shapes:\n",
    "            aligned.append(procrustes_align(s, mean_shape))\n",
    "        aligned = torch.stack(aligned)\n",
    "\n",
    "        new_mean = normalize_shape(aligned.mean(dim=0))\n",
    "        diff = torch.norm(mean_shape - new_mean)\n",
    "        mean_shape = new_mean\n",
    "\n",
    "        print(f\"Iteration {i} diff: {diff}\")\n",
    "\n",
    "        if diff < tol:\n",
    "            print(f\"Convergence reached after {i + 1} iterations.\")\n",
    "            break\n",
    "\n",
    "    return mean_shape\n",
    "\n",
    "\n"
   ],
   "id": "d9039997c327bd9b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "747afa22191e5ace"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:32:14.335670Z",
     "start_time": "2025-10-29T16:32:12.518110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from wings.config import PROCESSED_DATA_DIR\n",
    "\n",
    "countries = ['AT', 'GR', 'HR', 'HU', 'MD', 'PL', 'RO', 'SI']\n",
    "train_dataset = torch.load(\n",
    "    PROCESSED_DATA_DIR / \"mask_datasets\" / 'rectangle' / \"train_mask_dataset.pth\",\n",
    "    weights_only=False\n",
    ")\n",
    "max_n = len(train_dataset)\n",
    "print(max_n)\n",
    "_, _, orig_labels, _ = train_dataset[0]\n",
    "print(orig_labels.shape)\n"
   ],
   "id": "a93af3e7d0db2692",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-10-30 00:32:12.529\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mwings.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m40\u001B[0m - \u001B[1mPROJ_ROOT path is: /home/mkrajew/bees\u001B[0m\n",
      "\u001B[32m2025-10-30 00:32:12.601\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mwings.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m62\u001B[0m - \u001B[1mtorch.cuda.get_device_name()='NVIDIA RTX A3000 12GB Laptop GPU'\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15206\n",
      "torch.Size([38])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate GPA for Dataset",
   "id": "137b604fac02e87e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create train coordinates array",
   "id": "d2dd418a34b6ee01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:32:37.051791Z",
     "start_time": "2025-10-29T16:32:14.395920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=64, num_workers=8)\n",
    "orig_coords_list = []\n",
    "for _, _, labels, _ in tqdm(loader, desc=\"Loading orig_labels\", unit=\"batch\"):\n",
    "    orig_coords_list.append(labels.view(labels.size(0), -1, 2))  # we make shape (19, 2) from shape (38)\n",
    "orig_coords = torch.cat(orig_coords_list)\n",
    "\n",
    "print(orig_coords.shape)\n",
    "\n",
    "mean_coords = generalized_procrustes_analysis(orig_coords)\n",
    "print(mean_coords.shape)\n"
   ],
   "id": "817084fdc68b8ce4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading orig_labels: 100%|██████████| 238/238 [00:21<00:00, 11.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15206, 19, 2])\n",
      "Iteration 0 diff: 0.0001964124385267496\n",
      "Iteration 1 diff: 7.297820303620028e-08\n",
      "Convergence reached after 2 iterations.\n",
      "torch.Size([19, 2])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save mean_shape",
   "id": "d7cd977a165e8903"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:32:37.068576Z",
     "start_time": "2025-10-29T16:32:37.065972Z"
    }
   },
   "cell_type": "code",
   "source": "# torch.save(mean_coords, PROCESSED_DATA_DIR / \"mask_datasets\" / 'rectangle' / 'mean_shape2.pth')",
   "id": "16ed7168784f19d2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Permute coordinates",
   "id": "1f57bf17ea2a84bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:32:37.314315Z",
     "start_time": "2025-10-29T16:32:37.109601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "def solve_assignment(cost_matrix):\n",
    "    \"\"\"\n",
    "    cost_matrix: numpy array (n_mean, n_shape)\n",
    "    zwraca permutację idx: array length n_mean, idx[j] = index in shape matched to mean j\n",
    "    \"\"\"\n",
    "    r, c = linear_sum_assignment(cost_matrix)\n",
    "    idx = np.empty(cost_matrix.shape[0], dtype=int)\n",
    "    idx[r] = c\n",
    "    return idx\n",
    "\n",
    "\n",
    "def recover_order(mean_shape, unordered_shape, max_iter=5, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    mean_shape: torch tensor (n_points, 2)\n",
    "    unordered_shape: torch tensor (n_points, 2) - same points but random order/transform\n",
    "    Returns:\n",
    "        reordered_shape: torch tensor (n_points, 2) = unordered_shape[perm_idx]\n",
    "    \"\"\"\n",
    "    mean = mean_shape.to(device).float()\n",
    "    s = unordered_shape.to(device).float()\n",
    "    assert s.shape[0] == mean.shape[0] and mean.shape[1] == 2\n",
    "\n",
    "    mean_torch = normalize_shape(center_shape(mean))\n",
    "    shapes_torch = normalize_shape(center_shape(s))\n",
    "\n",
    "    mean_temp = mean_torch.cpu().numpy()\n",
    "    shapes_temp = shapes_torch.cpu().numpy()\n",
    "\n",
    "    cost = cdist(mean_temp, shapes_temp)  # (n,n)\n",
    "    index = solve_assignment(cost)  # idx[row]=col\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        perm = torch.tensor(index, dtype=torch.long, device=device)\n",
    "        s_perm = shapes_torch[perm]\n",
    "\n",
    "        r = procrustes_align(s_perm, mean_torch, only_matrix=True).cpu().numpy()\n",
    "        s_rot = shapes_temp @ r  # (n,2)\n",
    "        cost = cdist(mean_temp, s_rot)\n",
    "        new_idx = solve_assignment(cost)\n",
    "\n",
    "        if np.array_equal(new_idx, index):\n",
    "            break\n",
    "        index = new_idx\n",
    "\n",
    "    reordered_shape = unordered_shape[index]\n",
    "\n",
    "    return reordered_shape\n"
   ],
   "id": "65c2be96bd68be9f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test ordering coords",
   "id": "4a99c11a6dff9647"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load model and test dataset",
   "id": "60d8c2179c2cf37b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:32:41.225866Z",
     "start_time": "2025-10-29T16:32:37.328012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from wings.modeling.loss import DiceLoss\n",
    "from wings.config import MODELS_DIR\n",
    "from wings.modeling.litnet import LitNet\n",
    "\n",
    "checkpoint_path = MODELS_DIR / 'unet-rectangle-epoch=08-val_loss=0.14-unet-training-rectangle_1.ckpt'\n",
    "unet_model = torch.hub.load(\n",
    "    'mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=False\n",
    ")\n",
    "num_epochs = 60\n",
    "model = LitNet.load_from_checkpoint(checkpoint_path, model=unet_model, num_epochs=num_epochs, criterion=DiceLoss())\n",
    "model.eval()\n",
    "\n",
    "test_dataset = torch.load(\n",
    "    PROCESSED_DATA_DIR / \"mask_datasets\" / 'rectangle' / \"test_mask_dataset.pth\",\n",
    "    weights_only=False\n",
    ")\n",
    "max_n = len(test_dataset)\n"
   ],
   "id": "87bad4b507636364",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mkrajew/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test",
   "id": "bc0cf0e97136606c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:33:26.019090Z",
     "start_time": "2025-10-29T16:33:25.933104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from wings.visualizing.image_preprocess import mask_to_coords, unet_reverse_padding\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "n = np.random.randint(0, max_n)\n",
    "print(n)\n",
    "image, _, orig_labels, orig_size = test_dataset[n]\n",
    "\n",
    "total_mse = 0\n",
    "num_samples = 0\n",
    "bad_masks = 0\n",
    "\n",
    "output = model(image.cuda().unsqueeze(0))\n",
    "mask = torch.round(output).squeeze().detach().cpu().numpy()\n",
    "\n",
    "mask_coords = mask_to_coords(mask)\n",
    "if len(mask_coords) == 19:\n",
    "    mask_height, mask_width = mask.shape\n",
    "    orig_width, orig_height = orig_size\n",
    "\n",
    "    pad_left, pad_top, pad_right, pad_bottom = unet_reverse_padding(mask, orig_width, orig_height)\n",
    "\n",
    "    mask_coords = [(x - pad_left, y - pad_bottom) for x, y in mask_coords]\n",
    "\n",
    "    scale_x = orig_width / (mask_width - pad_right - pad_left)\n",
    "    scale_y = orig_height / (mask_height - pad_top - pad_bottom)\n",
    "    mask_coords = torch.tensor([(x * scale_x, y * scale_y) for x, y in mask_coords])\n",
    "\n",
    "    # print(f\"mask coordinates: {mask_coords}\")\n",
    "    # print(f\"original coordinates: {orig_labels}\")\n",
    "\n",
    "    reordered = recover_order(mean_coords, mask_coords)\n",
    "    orig = orig_labels.view(-1, 2)\n",
    "    print(orig.shape)\n",
    "    print(reordered.shape)\n",
    "    print(mean_squared_error(orig, reordered, multioutput='raw_values'))\n",
    "    for i in range(len(reordered)):\n",
    "        print(f\"{i + 1}:\\t{reordered[i]}\\t{orig[i]}\")\n",
    "else:\n",
    "    print(f\"Found {len(mask_coords)} spots in mask.\")"
   ],
   "id": "8d8c8d8fb3fb3e29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n",
      "torch.Size([19, 2])\n",
      "torch.Size([19, 2])\n",
      "[2.71185412 1.65336793]\n",
      "1:\ttensor([200.3686, 179.6421])\ttensor([203., 180.])\n",
      "2:\ttensor([220.7451, 176.2526])\ttensor([222., 177.])\n",
      "3:\ttensor([264.8941, 257.6000])\ttensor([266., 258.])\n",
      "4:\ttensor([275.0824, 206.7579])\ttensor([275., 206.])\n",
      "5:\ttensor([278.4784, 122.0210])\ttensor([282., 123.])\n",
      "6:\ttensor([346.4000, 264.3789])\ttensor([347., 265.])\n",
      "7:\ttensor([400.7372, 294.8842])\ttensor([400., 297.])\n",
      "8:\ttensor([380.3608, 271.1579])\ttensor([381., 273.])\n",
      "9:\ttensor([417.7177, 240.6526])\ttensor([420., 239.])\n",
      "10:\ttensor([393.9451, 220.3158])\ttensor([394., 219.])\n",
      "11:\ttensor([434.6980, 186.4211])\ttensor([435., 188.])\n",
      "12:\ttensor([438.0941, 145.7474])\ttensor([439., 147.])\n",
      "13:\ttensor([451.6784, 115.2421])\ttensor([455., 115.])\n",
      "14:\ttensor([465.2628, 288.1053])\ttensor([463., 289.])\n",
      "15:\ttensor([506.0157, 250.8211])\ttensor([507., 250.])\n",
      "16:\ttensor([587.5215, 210.1474])\ttensor([586., 212.])\n",
      "17:\ttensor([614.6902, 206.7579])\ttensor([615., 208.])\n",
      "18:\ttensor([624.8784, 179.6421])\ttensor([624., 182.])\n",
      "19:\ttensor([ 74.7137, 247.4316])\ttensor([ 76., 247.])\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
