{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GPA\n",
    "Generalized Procrustes analysis"
   ],
   "id": "9ad2e4ad2348ce21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:15:37.118195Z",
     "start_time": "2025-10-16T16:15:35.529346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def center_shape(x):\n",
    "    \"\"\"Removes translation by shifting the shape so that its centroid is at (0, 0).\"\"\"\n",
    "    return x - x.mean(dim=0, keepdim=True)\n",
    "\n",
    "\n",
    "def normalize_shape(x):\n",
    "    \"\"\"Scales the shape so that it has unit length (normalizes its size).\"\"\"\n",
    "    return x / torch.norm(x)\n",
    "\n",
    "\n",
    "def procrustes_align(x, y, only_matrix=False):\n",
    "    \"\"\"\n",
    "    Aligns shape X to shape Y by rotation (Procrustes alignment).\n",
    "    Assumes both shapes are already centered and normalized.\n",
    "    \"\"\"\n",
    "    # Orthogonal rotation matrix `r` computed via SVD\n",
    "    u, _, vt = torch.linalg.svd(x.T @ y)\n",
    "    r = u @ vt\n",
    "    if torch.det(r) < 0:\n",
    "        # det(r)<0 means that it is a flip, not a rotation\n",
    "        # flip last column of U\n",
    "        u[:, -1] *= -1\n",
    "        r = u @ vt\n",
    "    if only_matrix:\n",
    "        return r\n",
    "    return x @ r\n",
    "\n",
    "\n",
    "def generalized_procrustes_analysis(shapes, tol=1e-6, max_iter=100, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    Performs Generalized Procrustes Analysis (GPA) on a set of 2D shapes.\n",
    "\n",
    "    Args:\n",
    "        shapes (torch.Tensor): Tensor of shape (N, n_points, 2) containing N shapes.\n",
    "        tol (float): Convergence tolerance for mean shape updates.\n",
    "        max_iter (int): Maximum number of iterations allowed.\n",
    "        device (torch.device): Device on which to perform computations.\n",
    "\n",
    "    Returns:\n",
    "        mean_shape (torch.Tensor): The resulting mean shape of shape (n_points, 2).\n",
    "    \"\"\"\n",
    "    shapes = shapes.to(device, dtype=torch.float32)\n",
    "    shapes = torch.stack([normalize_shape(center_shape(s)) for s in shapes])\n",
    "    mean_shape = normalize_shape(shapes.mean(dim=0))\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        aligned = []\n",
    "        for s in shapes:\n",
    "            aligned.append(procrustes_align(s, mean_shape))\n",
    "        aligned = torch.stack(aligned)\n",
    "\n",
    "        new_mean = normalize_shape(aligned.mean(dim=0))\n",
    "        diff = torch.norm(mean_shape - new_mean)\n",
    "        mean_shape = new_mean\n",
    "\n",
    "        print(f\"Iteration {i} diff: {diff}\")\n",
    "\n",
    "        if diff < tol:\n",
    "            print(f\"Convergence reached after {i + 1} iterations.\")\n",
    "            break\n",
    "\n",
    "    return mean_shape\n",
    "\n",
    "\n"
   ],
   "id": "d9039997c327bd9b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "747afa22191e5ace"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:15:39.520906Z",
     "start_time": "2025-10-16T16:15:37.122856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from wings.config import PROCESSED_DATA_DIR\n",
    "\n",
    "countries = ['AT', 'GR', 'HR', 'HU', 'MD', 'PL', 'RO', 'SI']\n",
    "train_dataset = torch.load(\n",
    "    PROCESSED_DATA_DIR / \"mask_datasets\" / 'rectangle' / \"train_mask_dataset.pth\",\n",
    "    weights_only=False\n",
    ")\n",
    "max_n = len(train_dataset)\n",
    "print(max_n)\n",
    "_, _, orig_labels, _ = train_dataset[0]\n",
    "print(orig_labels.shape)\n"
   ],
   "id": "a93af3e7d0db2692",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-10-17 00:15:37.141\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mwings.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m40\u001B[0m - \u001B[1mPROJ_ROOT path is: /home/mkrajew/bees\u001B[0m\n",
      "\u001B[32m2025-10-17 00:15:37.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mwings.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m62\u001B[0m - \u001B[1mtorch.cuda.get_device_name()='NVIDIA RTX A3000 12GB Laptop GPU'\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15206\n",
      "torch.Size([38])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate GPA for Dataset",
   "id": "137b604fac02e87e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create train coordinates array",
   "id": "d2dd418a34b6ee01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:16:00.576040Z",
     "start_time": "2025-10-16T16:15:39.625153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=64, num_workers=8)\n",
    "orig_coords_list = []\n",
    "for _, _, labels, _ in tqdm(loader, desc=\"Loading orig_labels\", unit=\"batch\"):\n",
    "    orig_coords_list.append(labels.view(labels.size(0), -1, 2))  # we make shape (19, 2) from shape (38)\n",
    "orig_coords = torch.cat(orig_coords_list)\n",
    "\n",
    "print(orig_coords.shape)\n",
    "\n",
    "mean_coords = generalized_procrustes_analysis(orig_coords)\n",
    "print(mean_coords.shape)\n"
   ],
   "id": "817084fdc68b8ce4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading orig_labels: 100%|██████████| 238/238 [00:21<00:00, 10.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15206, 19, 2])\n",
      "Iteration 0 diff: 0.0001964124385267496\n",
      "Iteration 1 diff: 7.297820303620028e-08\n",
      "Convergence reached after 2 iterations.\n",
      "torch.Size([19, 2])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save mean_shape",
   "id": "d7cd977a165e8903"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:24:37.608811Z",
     "start_time": "2025-10-16T16:24:37.602865Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(mean_coords, PROCESSED_DATA_DIR / \"mask_datasets\" / 'rectangle' / 'mean_shape2.pth')",
   "id": "16ed7168784f19d2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Permute coordinates",
   "id": "1f57bf17ea2a84bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:16:00.966954Z",
     "start_time": "2025-10-16T16:16:00.594221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "def solve_assignment(cost_matrix):\n",
    "    \"\"\"\n",
    "    cost_matrix: numpy array (n_mean, n_shape)\n",
    "    zwraca permutację idx: array length n_mean, idx[j] = index in shape matched to mean j\n",
    "    \"\"\"\n",
    "    r, c = linear_sum_assignment(cost_matrix)\n",
    "    idx = np.empty(cost_matrix.shape[0], dtype=int)\n",
    "    idx[r] = c\n",
    "    return idx\n",
    "\n",
    "\n",
    "def recover_order(mean_shape, unordered_shape, max_iter=5, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    mean_shape: torch tensor (n_points, 2)\n",
    "    unordered_shape: torch tensor (n_points, 2) - same points but random order/transform\n",
    "    Returns:\n",
    "        reordered_shape: torch tensor (n_points, 2) = unordered_shape[perm_idx]\n",
    "    \"\"\"\n",
    "    mean = mean_shape.to(device).float()\n",
    "    s = unordered_shape.to(device).float()\n",
    "    assert s.shape[0] == mean.shape[0] and mean.shape[1] == 2\n",
    "\n",
    "    mean_torch = normalize_shape(center_shape(mean))\n",
    "    shapes_torch = normalize_shape(center_shape(s))\n",
    "\n",
    "    mean_temp = mean_torch.cpu().numpy()\n",
    "    shapes_temp = shapes_torch.cpu().numpy()\n",
    "\n",
    "    cost = cdist(mean_temp, shapes_temp)  # (n,n)\n",
    "    index = solve_assignment(cost)  # idx[row]=col\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        perm = torch.tensor(index, dtype=torch.long, device=device)\n",
    "        s_perm = shapes_torch[perm]\n",
    "\n",
    "        r = procrustes_align(s_perm, mean_torch, only_matrix=True).cpu().numpy()\n",
    "        s_rot = shapes_temp @ r  # (n,2)\n",
    "        cost = cdist(mean_temp, s_rot)\n",
    "        new_idx = solve_assignment(cost)\n",
    "\n",
    "        if np.array_equal(new_idx, index):\n",
    "            break\n",
    "        index = new_idx\n",
    "\n",
    "    reordered_shape = unordered_shape[index]\n",
    "\n",
    "    return reordered_shape\n"
   ],
   "id": "65c2be96bd68be9f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test ordering coords",
   "id": "4a99c11a6dff9647"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load model and test dataset",
   "id": "60d8c2179c2cf37b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:16:03.754163Z",
     "start_time": "2025-10-16T16:16:00.979325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from wings.modeling.loss import DiceLoss\n",
    "from wings.config import MODELS_DIR\n",
    "from wings.modeling.litnet import LitNet\n",
    "\n",
    "checkpoint_path = MODELS_DIR / 'unet-rectangle-epoch=08-val_loss=0.14-unet-training-rectangle_1.ckpt'\n",
    "unet_model = torch.hub.load(\n",
    "    'mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=False\n",
    ")\n",
    "num_epochs = 60\n",
    "model = LitNet.load_from_checkpoint(checkpoint_path, model=unet_model, num_epochs=num_epochs, criterion=DiceLoss())\n",
    "model.eval()\n",
    "\n",
    "test_dataset = torch.load(\n",
    "    PROCESSED_DATA_DIR / \"mask_datasets\" / 'rectangle' / \"test_mask_dataset.pth\",\n",
    "    weights_only=False\n",
    ")\n",
    "max_n = len(test_dataset)\n"
   ],
   "id": "87bad4b507636364",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mkrajew/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test",
   "id": "bc0cf0e97136606c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:17:34.142779Z",
     "start_time": "2025-10-16T16:17:34.056152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from wings.visualizing.image_preprocess import mask_to_coords, unet_reverse_padding\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "n = np.random.randint(0, max_n)\n",
    "print(n)\n",
    "image, _, orig_labels, orig_size = test_dataset[n]\n",
    "\n",
    "total_mse = 0\n",
    "num_samples = 0\n",
    "bad_masks = 0\n",
    "\n",
    "output = model(image.cuda().unsqueeze(0))\n",
    "mask = torch.round(output).squeeze().detach().cpu().numpy()\n",
    "try:\n",
    "    mask_coords = mask_to_coords(mask, max_iter=1)\n",
    "\n",
    "    mask_height, mask_width = mask.shape\n",
    "    orig_width, orig_height = orig_size\n",
    "\n",
    "    pad_left, pad_top, pad_right, pad_bottom = unet_reverse_padding(mask, orig_width, orig_height)\n",
    "\n",
    "    mask_coords = [(x - pad_left, y - pad_bottom) for x, y in mask_coords]\n",
    "\n",
    "    scale_x = orig_width / (mask_width - pad_right - pad_left)\n",
    "    scale_y = orig_height / (mask_height - pad_top - pad_bottom)\n",
    "    mask_coords = torch.tensor([(x * scale_x, y * scale_y) for x, y in mask_coords])\n",
    "\n",
    "    # print(f\"mask coordinates: {mask_coords}\")\n",
    "    # print(f\"original coordinates: {orig_labels}\")\n",
    "\n",
    "    reordered = recover_order(mean_coords, mask_coords)\n",
    "    orig = orig_labels.view(-1, 2)\n",
    "    print(orig.shape)\n",
    "    print(reordered.shape)\n",
    "    print(mean_squared_error(orig, reordered, multioutput='raw_values'))\n",
    "    for i in range(len(reordered)):\n",
    "        print(f\"{i + 1}:\\t{reordered[i]}\\t{orig[i]}\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "id": "8d8c8d8fb3fb3e29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1294\n",
      "torch.Size([19, 2])\n",
      "torch.Size([19, 2])\n",
      "[2.94414702 1.02988567]\n",
      "1:\ttensor([209.0980, 175.1579])\ttensor([211., 175.])\n",
      "2:\ttensor([232.7059, 171.7895])\ttensor([232., 172.])\n",
      "3:\ttensor([276.5490, 252.6316])\ttensor([278., 255.])\n",
      "4:\ttensor([276.5490, 198.7368])\ttensor([279., 199.])\n",
      "5:\ttensor([283.2941, 117.8947])\ttensor([285., 117.])\n",
      "6:\ttensor([344.0000, 259.3684])\ttensor([346., 260.])\n",
      "7:\ttensor([401.3333, 293.0526])\ttensor([401., 295.])\n",
      "8:\ttensor([381.0981, 272.8421])\ttensor([385., 272.])\n",
      "9:\ttensor([428.3137, 239.1579])\ttensor([428., 238.])\n",
      "10:\ttensor([397.9608, 215.5789])\ttensor([399., 215.])\n",
      "11:\ttensor([438.4314, 185.2632])\ttensor([439., 186.])\n",
      "12:\ttensor([445.1765, 144.8421])\ttensor([445., 144.])\n",
      "13:\ttensor([455.2941, 114.5263])\ttensor([458., 114.])\n",
      "14:\ttensor([468.7843, 286.3158])\ttensor([471., 287.])\n",
      "15:\ttensor([509.2549, 252.6316])\ttensor([509., 252.])\n",
      "16:\ttensor([583.4510, 212.2105])\ttensor([584., 211.])\n",
      "17:\ttensor([617.1765, 208.8421])\ttensor([617., 208.])\n",
      "18:\ttensor([627.2941, 178.5263])\ttensor([627., 178.])\n",
      "19:\ttensor([ 84.3137, 249.2632])\ttensor([ 87., 248.])\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
